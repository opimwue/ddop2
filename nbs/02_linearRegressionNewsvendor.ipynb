{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deccc8a9-8a7b-483c-9379-14db1571b689",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b0c691-8934-45ac-aa8e-458b1ccdadd7",
   "metadata": {},
   "source": [
    "# Linear Regression Newsvendor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5048b4c8-599d-47e6-b7bc-991945e480ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp newsvendor._LinearRegressionNewsvendor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85bbed0-d753-4fa1-afd7-86a985339538",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0043dda5-8a7b-4530-9448-0a00e38f4ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from ddop2.newsvendor._base import BaseNewsvendor, DataDrivenMixin\n",
    "from ddop2.utils.validation import check_cu_co\n",
    "import numpy as np\n",
    "import pulp\n",
    "from sklearn.utils.validation import check_array, check_is_fitted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6eb384-2278-4baa-ab49-84a88876d722",
   "metadata": {},
   "source": [
    "## Linear Regression Newsvendor Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916cd68b-f8e8-40a9-87d2-a158b5dbfb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class LinearRegressionNewsvendor(BaseNewsvendor, DataDrivenMixin):\n",
    "    \n",
    "    \"\"\"A linear regression model to solve the Newsvendor problem\n",
    "\n",
    "    This class implements the approach described in [1].\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cu : {array-like of shape (n_outputs,), Number or None}, default=None\n",
    "       The underage costs per unit. If None, then underage costs are one\n",
    "       for each target variable\n",
    "    co : {array-like of shape (n_outputs,), Number or None}, default=None\n",
    "       The overage costs per unit. If None, then overage costs are one\n",
    "       for each target variable\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    n_features_ : int\n",
    "        The number of features when ``fit`` is performed.\n",
    "    n_outputs_ : int\n",
    "        The number of outputs.\n",
    "    cu_ : ndarray, shape (n_outputs,)\n",
    "        Validated underage costs.\n",
    "    co_ : ndarray, shape (n_outputs,)\n",
    "        Validated overage costs.\n",
    "    feature_weights_: array of shape (n_outputs, n_features)\n",
    "        The calculated feature weights\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Gah-Yi Ban, Cynthia Rudin, \"The Big Data Newsvendor: Practical Insights\n",
    "        from Machine Learning\", 2018.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from ddop.datasets import load_yaz\n",
    "    >>> from ddop.newsvendor import LinearRegressionNewsvendor\n",
    "    >>> from sklearn.model_selection import train_test_split\n",
    "    >>> X, Y = load_yaz(include_prod=['STEAK'],return_X_y=True)\n",
    "    >>> cu,co = 15,10\n",
    "    >>> X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, shuffle=False, random_state=0)\n",
    "    >>> mdl = LinearRegressionNewsvendor(cu=15, co=10)\n",
    "    >>> mdl.fit(X_train, Y_train)\n",
    "    >>> mdl.score(X_test, Y_test)\n",
    "    TODO: ADD SCORE\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cu=None, co=None):\n",
    "        super().__init__(\n",
    "            cu=cu,\n",
    "            co=co)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        \"\"\" Calculate the feature weights for estimator\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The training input samples.\n",
    "        y : array-like of shape (n_samples, n_outputs)\n",
    "            The target values.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        self : LinearRegressionNewsvendor\n",
    "            Fitted estimator\n",
    "        \"\"\"\n",
    "        X, y = self._validate_data(X, y, multi_output=True)\n",
    "\n",
    "        if y.ndim == 1:\n",
    "            y = np.reshape(y, (-1, 1))\n",
    "\n",
    "        # Determine output settings\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "        self.n_features_ = X.shape[1]\n",
    "        self.n_outputs_ = y.shape[1]\n",
    "\n",
    "        # Check and format under- and overage costs\n",
    "        self.cu_, self.co_ = check_cu_co(self.cu, self.co, self.n_outputs_)\n",
    "\n",
    "        n_samples = X.shape[0]\n",
    "\n",
    "        feature_weights = []\n",
    "        intercept = []\n",
    "\n",
    "        # Define and solve LpProblem for each target variable\n",
    "        # Then safe the calculated feature weights\n",
    "        for k in range(self.n_outputs_):\n",
    "            opt_model = pulp.LpProblem(sense=pulp.LpMinimize)\n",
    "            n = np.arange(n_samples)\n",
    "            p = np.arange(self.n_features_)\n",
    "            q0 = pulp.LpVariable('q0')\n",
    "            q = pulp.LpVariable.dicts('q', p)\n",
    "            u = pulp.LpVariable.dicts('u', n, lowBound=0)\n",
    "            o = pulp.LpVariable.dicts('o', n, lowBound=0)\n",
    "\n",
    "            overage = pulp.LpAffineExpression([(u[i], self.cu_[k]) for i in n])\n",
    "            underage = pulp.LpAffineExpression([(o[i], self.co_[k]) for i in n])\n",
    "\n",
    "            objective = (underage + overage)/len(n)\n",
    "            opt_model.setObjective(objective)\n",
    "\n",
    "            for i in n:\n",
    "                opt_model += u[i] >= y[i,k] - q0 - sum([q[j] * X[i, j] for j in p])\n",
    "                opt_model += o[i] >= q0 + sum([q[j] * X[i, j] for j in p]) - y[i,k]\n",
    "            opt_model.solve()\n",
    "\n",
    "            feature_weights_yk = []\n",
    "\n",
    "            for feature in q:\n",
    "                feature_weights_yk += [q[feature].value()]\n",
    "\n",
    "            feature_weights.append(feature_weights_yk)\n",
    "            intercept.append(q0.value())\n",
    "\n",
    "        #make sure no weight is None\n",
    "        feature_weights = np.array(feature_weights)\n",
    "        feature_weights[feature_weights == None] = 0.0\n",
    "        self.feature_weights_ = feature_weights\n",
    "        self.intercept_ = intercept\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _validate_X_predict(self, X):\n",
    "        \n",
    "        \"\"\"Validate X whenever one tries to predict\"\"\"\n",
    "        X = check_array(X)\n",
    "\n",
    "        n_features = X.shape[1]\n",
    "        if self.n_features_ != n_features:\n",
    "            raise ValueError(\"Number of features of the model must match the input. \"\n",
    "                             \"Model n_features is %s and input n_features is %s \"\n",
    "                             % (self.n_features_, n_features))\n",
    "        return X\n",
    "\n",
    "    def predict(self, X):\n",
    "        \n",
    "        \"\"\"Predict value for X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The input samples to predict.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        y : array-like of shape (n_samples, n_outputs)\n",
    "            The predicted values\n",
    "        \"\"\"\n",
    "\n",
    "        check_is_fitted(self)\n",
    "        X = self._validate_X_predict(X)\n",
    "\n",
    "        pred = X.dot(self.feature_weights_.T)+self.intercept_\n",
    "\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6ec563-996f-4fa6-aa54-ba8f30ab7128",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84786e80-9a03-42da-b266-6252859c18c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f6e7c7-0dcd-4b98-b7fc-88ed9994d0f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010f43d9-2c0c-4d99-ab28-e25934c70210",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dddex",
   "language": "python",
   "name": "dddex"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
