{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deccc8a9-8a7b-483c-9379-14db1571b689",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b0c691-8934-45ac-aa8e-458b1ccdadd7",
   "metadata": {},
   "source": [
    "# Exponential Smoothing Newsvendor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5048b4c8-599d-47e6-b7bc-991945e480ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp newsvendor._ExponentialSmoothingNewsvendor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241c9a8e-16d1-4d06-9f21-5586976d3150",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0043dda5-8a7b-4530-9448-0a00e38f4ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from scipy.stats import norm\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from ddop2.newsvendor._base import BaseNewsvendor, ClassicMixin\n",
    "from ddop2.utils.validation import check_cu_co\n",
    "from sklearn.utils.validation import check_array\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6eb384-2278-4baa-ab49-84a88876d722",
   "metadata": {},
   "source": [
    "## Exponential Smoothing Newsvendor Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916cd68b-f8e8-40a9-87d2-a158b5dbfb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class ExponentialSmoothingNewsvendor(BaseNewsvendor, ClassicMixin):\n",
    "    \n",
    "    \"\"\"\n",
    "    A SEO newsvendor model with exponential smoothing as underlying forecaster\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cu : {array-like of shape (n_outputs,), Number or None}, default=None\n",
    "       The underage costs per unit. If None, then underage costs are one\n",
    "       for each target variable\n",
    "    co : {array-like of shape (n_outputs,), Number or None}, default=None\n",
    "       The overage costs per unit. If None, then overage costs are one\n",
    "       for each target variable\n",
    "    trend : {\"add\", \"mul\", \"additive\", \"multiplicative\", None}, default=None\n",
    "        Type of trend component.\n",
    "    damped_trend : bool, optional (default=None)\n",
    "        Should the trend component be damped.\n",
    "    seasonal : {\"add\", \"mul\", \"additive\", \"multiplicative\", None}, default=None\n",
    "        Type of seasonal component.\n",
    "    seasonal_periods : int, default=None\n",
    "        The number of periods in a complete seasonal cycle, e.g., 4 for\n",
    "        quarterly data or 7 for daily data with a weekly cycle.\n",
    "    initialization_method : str, optional\n",
    "        Method for initialize the recursions. One of:\n",
    "        * 'estimated'\n",
    "        * 'heuristic'\n",
    "        * 'legacy-heuristic'\n",
    "        * 'known'\n",
    "        If 'known' initialization is used, then `initial_level`\n",
    "        must be passed, as well as `initial_trend` and `initial_seasonal` if\n",
    "        applicable. Default is 'estimated'.\n",
    "    initial_level : float, optional\n",
    "        The initial level component. Required if estimation method is \"known\".\n",
    "        If set using either \"estimated\" or \"heuristic\" this value is used.\n",
    "        This allows one or more of the initial values to be set while\n",
    "        deferring to the heuristic for others or estimating the unset\n",
    "        parameters.\n",
    "    initial_trend : float, optional\n",
    "        The initial trend component. Required if estimation method is \"known\".\n",
    "        If set using either \"estimated\" or \"heuristic\" this value is used.\n",
    "        This allows one or more of the initial values to be set while\n",
    "        deferring to the heuristic for others or estimating the unset\n",
    "        parameters.\n",
    "    initial_seasonal : array_like, optional\n",
    "        The initial seasonal component. An array of length `seasonal`\n",
    "        or length `seasonal - 1` (in which case the last initial value\n",
    "        is computed to make the average effect zero). Only used if\n",
    "        initialization is 'known'. Required if estimation method is \"known\".\n",
    "        If set using either \"estimated\" or \"heuristic\" this value is used.\n",
    "        This allows one or more of the initial values to be set while\n",
    "        deferring to the heuristic for others or estimating the unset\n",
    "        parameters.\n",
    "    use_boxcox : {True, False, 'log', float}, optional\n",
    "        Should the Box-Cox transform be applied to the data first? If 'log'\n",
    "        then apply the log. If float then use lambda equal to float.\n",
    "    smoothing_level : float, optional\n",
    "        The alpha value of the simple exponential smoothing, if the value\n",
    "        is set then this value will be used as the value.\n",
    "    smoothing_trend : float, optional\n",
    "        The beta value of the Holt's trend method, if the value is\n",
    "        set then this value will be used as the value.\n",
    "    smoothing_seasonal : float, optional\n",
    "        The gamma value of the holt winters seasonal method, if the value\n",
    "        is set then this value will be used as the value.\n",
    "    optimized : bool, optional\n",
    "        Estimate model parameters by maximizing the log-likelihood\n",
    "    remove_bias : bool, optional\n",
    "        Remove bias from forecast values and fitted values by enforcing\n",
    "        that the average residual is equal to zero.\n",
    "    method : str, default \"L-BFGS-B\"\n",
    "        The minimizer used. Valid options are \"L-BFGS-B\" (default), \"TNC\",\n",
    "        \"SLSQP\", \"Powell\", \"trust-constr\", \"basinhopping\" (also \"bh\") and\n",
    "        \"least_squares\" (also \"ls\"). basinhopping tries multiple starting\n",
    "        values in an attempt to find a global minimizer in non-convex\n",
    "        problems, and so is slower than the others.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    n_outputs_ : int\n",
    "        The number of outputs when ``fit`` is performed.\n",
    "    cu_ : ndarray, shape (n_outputs,)\n",
    "        Validated underage costs.\n",
    "    co_ : ndarray, shape (n_outputs,)\n",
    "        Validated overage costs.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Hyndman, Rob J., and George Athanasopoulos. Forecasting: principles\n",
    "        and practice. OTexts, 2014.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from ddop.datasets import load_yaz\n",
    "    >>> from ddop.newsvendor import ExponentialSmoothingNewsvendor\n",
    "    >>> from sklearn.model_selection import train_test_split\n",
    "    >>> X, Y = load_yaz(include_prod=['STEAK'],return_X_y=True)\n",
    "    >>> Y_train, Y_test = train_test_split(Y, test_size=0.25, shuffle=False, random_state=0)\n",
    "    >>> mdl = ExponentialSmoothingNewsvendor(cu, co, 'add', False, 'add',7)\n",
    "    >>> mdl.fit(Y_train)\n",
    "    >>> mdl.score(Y_test)\n",
    "    TODO: ADD SCORE\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            cu=None,\n",
    "            co=None,\n",
    "            trend=None,\n",
    "            damped_trend=False,\n",
    "            seasonal=None,\n",
    "            seasonal_periods=None,\n",
    "            initialization_method=\"estimated\",\n",
    "            initial_level=None,\n",
    "            initial_trend=None,\n",
    "            initial_seasonal=None,\n",
    "            use_boxcox=False,\n",
    "            smoothing_level=None,\n",
    "            smoothing_trend=None,\n",
    "            smoothing_seasonal=None,\n",
    "            optimized=True,\n",
    "            remove_bias=False,\n",
    "            method=\"L-BFGS-B\"\n",
    "    ):\n",
    "        self.cu = cu\n",
    "        self.co = co\n",
    "        self.trend = trend\n",
    "        self.damped_trend = damped_trend\n",
    "        self.seasonal = seasonal\n",
    "        self.seasonal_periods = seasonal_periods\n",
    "        self.initialization_method = initialization_method\n",
    "        self.initial_level = initial_level\n",
    "        self.initial_trend = initial_trend\n",
    "        self.initial_seasonal = initial_seasonal\n",
    "        self.use_boxcox = use_boxcox\n",
    "        self.smoothing_level = smoothing_level\n",
    "        self.smoothing_trend = smoothing_trend\n",
    "        self.smoothing_seasonal = smoothing_seasonal\n",
    "        self.optimized = optimized\n",
    "        self.remove_bias = remove_bias\n",
    "        self.method = method\n",
    "        super().__init__(\n",
    "            cu=cu,\n",
    "            co=co)\n",
    "\n",
    "    def fit(self, y, X=None):\n",
    "        \n",
    "        \"\"\"Fit the model to the training data y.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : array-like of shape (n_samples, n_outputs)\n",
    "            The target values.\n",
    "        X : array-like of shape (n_samples, n_features), optional (default=None)\n",
    "            Exogenous variables are ignored\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        self : HoltWintersNewsvendor\n",
    "            Fitted estimator\n",
    "        \"\"\"\n",
    "\n",
    "        y = check_array(y, ensure_2d=False)\n",
    "\n",
    "        if y.ndim == 1:\n",
    "            y = np.reshape(y, (-1, 1))\n",
    "\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "        self.n_outputs_ = y.shape[1]\n",
    "\n",
    "        # Check and format under- and overage costs\n",
    "        self.cu_, self.co_ = check_cu_co(self.cu, self.co, self.n_outputs_)\n",
    "\n",
    "        forecasters = [ExponentialSmoothing(\n",
    "            endog=y[:, i],\n",
    "            trend=self.trend,\n",
    "            damped_trend=self.damped_trend,\n",
    "            seasonal=self.seasonal,\n",
    "            seasonal_periods=self.seasonal_periods,\n",
    "            initialization_method=self.initialization_method,\n",
    "            initial_level=self.initial_level,\n",
    "            initial_trend=self.initial_trend,\n",
    "            initial_seasonal=self.initial_seasonal,\n",
    "            use_boxcox=self.use_boxcox) for i in range(self.n_outputs_)]\n",
    "\n",
    "        fitted_forecasters = [forecasters[i].fit(\n",
    "            smoothing_level=self.smoothing_level,\n",
    "            smoothing_trend=self.smoothing_trend,\n",
    "            smoothing_seasonal=self.smoothing_seasonal,\n",
    "            optimized=self.optimized,\n",
    "            remove_bias=self.remove_bias,\n",
    "            method=self.method) for i in range(self.n_outputs_)]\n",
    "\n",
    "        error = np.array([y[:, i] - fitted_forecasters[i].fittedvalues for i in range(self.n_outputs_)])\n",
    "        error_mean = error.mean(axis=1)\n",
    "        error_std = error.std(axis=1)\n",
    "\n",
    "        mae = np.array([mean_absolute_error(y[:, i], fitted_forecasters[i].fittedvalues)\n",
    "                        for i in range(self.n_outputs_)])\n",
    "\n",
    "        self.safety_buffer_mae = np.array(\n",
    "            [1.25 * mae[i] * norm.ppf(self.cu_[i] / (self.co_[i] + self.cu_[i])) for i in range(self.n_outputs_)])\n",
    "\n",
    "        self.safety_buffer_ = np.array(\n",
    "            [norm(error_mean[i], error_std[i]).ppf(self.cu_[i] / (self.co_[i] + self.cu_[i])) for i in\n",
    "             range(self.n_outputs_)])\n",
    "\n",
    "        self.forecasters_ = fitted_forecasters\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, n_steps=1):\n",
    "        \n",
    "        \"\"\"Predict n time-steps\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_steps : int, default=1\n",
    "            The number of steps to predict ahead\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        y : array-like of shape (n, n_outputs)\n",
    "            The predicted values\n",
    "        \"\"\"\n",
    "\n",
    "        forecasts = np.array([forecaster.forecast(n_steps) for forecaster in self.forecasters_]).T\n",
    "        pred = forecasts + self.safety_buffer_\n",
    "\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb806b6-0e48-499d-b1bb-06b82c8eeab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84786e80-9a03-42da-b266-6252859c18c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f6e7c7-0dcd-4b98-b7fc-88ed9994d0f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010f43d9-2c0c-4d99-ab28-e25934c70210",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dddex",
   "language": "python",
   "name": "dddex"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
