{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deccc8a9-8a7b-483c-9379-14db1571b689",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b0c691-8934-45ac-aa8e-458b1ccdadd7",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5048b4c8-599d-47e6-b7bc-991945e480ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp newsvendor._DeepLearningNewsvendor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dabb1f-c6df-41eb-8645-e2a15216ab73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0043dda5-8a7b-4530-9448-0a00e38f4ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from ddop2.newsvendor._base import BaseNewsvendor, DataDrivenMixin\n",
    "from ddop2.utils.validation import check_cu_co\n",
    "\n",
    "\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "import numpy as np\n",
    "\n",
    "ACTIVATIONS = ['elu', 'selu', 'linear', 'tanh', 'relu', 'softmax', 'softsign', 'softplus',\n",
    "               'sigmoid', 'hard_sigmoid', 'exponential']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6eb384-2278-4baa-ab49-84a88876d722",
   "metadata": {},
   "source": [
    "## Check cost parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916cd68b-f8e8-40a9-87d2-a158b5dbfb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class DeepLearningNewsvendor(BaseNewsvendor, DataDrivenMixin):\n",
    "\n",
    "\n",
    "    \n",
    "    \"\"\"A Deep-Learning model to solve the Newsvendor problem.\n",
    "\n",
    "    This class implements the approach described in [1].\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cu : {array-like of shape (n_outputs,), Number or None}, default=None\n",
    "       The underage costs per unit. If None, then underage costs are one\n",
    "       for each target variable\n",
    "    co : {array-like of shape (n_outputs,), Number or None}, default=None\n",
    "       The overage costs per unit. If None, then overage costs are one\n",
    "       for each target variable\n",
    "    neurons : list, default=[100,50]\n",
    "        The ith element represents the number of neurons in the ith hidden layer\n",
    "        Only used when hidden_layers='custom'.\n",
    "    activations : list, default=['relu','relu']\n",
    "        The ith element of the list represents the activation function of the ith layer.\n",
    "        Valid activation functions are: 'elu', 'selu', 'linear', 'tanh', 'relu', 'softmax',\n",
    "        'softsign', 'softplus','sigmoid', 'hard_sigmoid', 'exponential'.\n",
    "        Only used when hidden_layers='custom'.\n",
    "    optimizer: {'adam', 'sgd'}, default='adam'\n",
    "        The optimizer to be used.\n",
    "    epochs: int, default=100\n",
    "        Number of epochs to train the model\n",
    "    random_state: int, RandomState instance, default=None\n",
    "        Pass an int for reproducible results across multiple function calls.\n",
    "    verbose: int 0, 1, or 2, default=0\n",
    "        Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    model_ : tensorflow.keras.Sequential\n",
    "        The underlying model\n",
    "    n_features_ : int\n",
    "        The number of features when ``fit`` is performed.\n",
    "    n_outputs_ : int\n",
    "        The number of outputs.\n",
    "    cu_ : ndarray, shape (n_outputs,)\n",
    "        Validated underage costs.\n",
    "    co_ : ndarray, shape (n_outputs,)\n",
    "        Validated overage costs.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Afshin Oroojlooyjadid, Lawrence V. Snyder, Martin Takáˇc,\n",
    "            \"Applying Deep Learning to the Newsvendor Problem\", 2018.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from ddop.datasets import load_yaz\n",
    "    >>> from ddop.newsvendor import DeepLearningNewsvendor\n",
    "    >>> from sklearn.model_selection import train_test_split\n",
    "    >>> X, Y = load_yaz(include_prod=['STEAK'],return_X_y=True)\n",
    "    >>> cu,co = 15,10\n",
    "    >>> X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, shuffle=False, random_state=0)\n",
    "    >>> mdl = DeepLearningNewsvendor(cu, co)\n",
    "    >>> mdl.fit(X_train, Y_train)\n",
    "    >>> mdl.score(X_test, Y_test)\n",
    "    TODO: ADD SCORE\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cu=None, co=None, neurons=[100, 50], activations=['relu', 'relu'], optimizer='adam', epochs=100,\n",
    "                 random_state=None, verbose=0):\n",
    "\n",
    "        from tensorflow.keras.models import Sequential\n",
    "        from tensorflow.keras.layers import Dense\n",
    "        from tensorflow.keras.backend import switch, less\n",
    "        from tensorflow.keras.backend import sum as ksum\n",
    "        from tensorflow import cast\n",
    "        from tensorflow.random import set_seed\n",
    "\n",
    "\n",
    "        self.neurons = neurons\n",
    "        self.activations = activations\n",
    "        self.optimizer = optimizer\n",
    "        self.epochs = epochs\n",
    "        self.random_state = random_state\n",
    "        self.verbose = verbose\n",
    "        super().__init__(\n",
    "            cu=cu,\n",
    "            co=co)\n",
    "\n",
    "    def _nv_loss(self, cu, co):\n",
    "        \n",
    "        \"\"\"Create a newsvendor loss function with the given under- and overage costs\"\"\"\n",
    "\n",
    "        def customized_loss(y_true, y_pred):\n",
    "            y_true = cast(y_true, y_pred.dtype)\n",
    "            loss = switch(less(y_pred, y_true), cu * (y_true - y_pred), co * (y_pred - y_true))\n",
    "            return ksum(loss)\n",
    "\n",
    "        return customized_loss\n",
    "\n",
    "    def _create_model(self):\n",
    "        \n",
    "        \"\"\"Create model\"\"\"\n",
    "        neurons = self.neurons\n",
    "        activations = self.activations\n",
    "        n_features = self.n_features_\n",
    "        n_outputs = self.n_outputs_\n",
    "\n",
    "        set_seed(self.random_state)\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        for size, activation in zip(neurons, activations):\n",
    "            model.add(Dense(units=size, activation=activation))\n",
    "        model.add(Dense(n_outputs))\n",
    "        model.build((None, n_features))\n",
    "\n",
    "        model.compile(loss=self._nv_loss(self.cu_, self.co_), optimizer=self.optimizer)\n",
    "\n",
    "        return model\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        \"\"\"Fit the model to the training set (X, y).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The training input samples.\n",
    "        y : array-like of shape (n_samples, n_outputs)\n",
    "            The target values.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        self : DeepLearningNewsvendor\n",
    "            Fitted estimator\n",
    "        \"\"\"\n",
    "\n",
    "        # Validate input parameters\n",
    "        self._validate_hyperparameters()\n",
    "\n",
    "        X, y = self._validate_data(X, y, multi_output=True)\n",
    "\n",
    "        if y.ndim == 1:\n",
    "            y = np.reshape(y, (-1, 1))\n",
    "\n",
    "        # Determine output settings\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "        self.n_features_ = X.shape[1]\n",
    "        self.n_outputs_ = y.shape[1]\n",
    "\n",
    "        # Check and format under- and overage costs\n",
    "        self.cu_, self.co_ = check_cu_co(self.cu, self.co, self.n_outputs_)\n",
    "        model = self._create_model()\n",
    "        model.fit(X, y, epochs=self.epochs, verbose=self.verbose)\n",
    "        self.model_ = model\n",
    "        return self\n",
    "\n",
    "    def _validate_hyperparameters(self):\n",
    "        \n",
    "        \"\"\"validate hyperparameters\"\"\"\n",
    "\n",
    "        # Make sure self.neurons is a list\n",
    "        neurons = self.neurons\n",
    "        if not hasattr(neurons, \"__iter__\"):\n",
    "            neurons = [neurons]\n",
    "        neurons = list(neurons)\n",
    "\n",
    "        # Make sure self.activations is a list\n",
    "        activations = self.activations\n",
    "        if not hasattr(activations, \"__iter__\"):\n",
    "            activations = [activations]\n",
    "        activations = list(activations)\n",
    "\n",
    "        if np.any(np.array(neurons) <= 0):\n",
    "            raise ValueError(\"neurons must be > 0, got %s.\" %\n",
    "                             self.neurons)\n",
    "\n",
    "        if np.any(np.array([activation not in ACTIVATIONS for activation in activations])):\n",
    "            raise ValueError(\"Invalid activation function in activations. Supported are %s but got %s\"\n",
    "                             % (list(ACTIVATIONS), activations))\n",
    "\n",
    "        if len(neurons) != len(activations):\n",
    "            raise ValueError(\"Neurons and activations must have same length but neurons is of length %s and \"\n",
    "                             \"activations %s \" % (len(neurons), len(activations)))\n",
    "\n",
    "        if self.verbose not in [0, 1, 2]:\n",
    "            raise ValueError(\"verbose must be either 0, 1 or 2, got %s.\" %\n",
    "                             self.verbose)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \n",
    "        \"\"\"Predict values for X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The input samples to predict.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        y : array-like of shape (n_samples, n_outputs)\n",
    "            The predicted values\n",
    "        \"\"\"\n",
    "        check_is_fitted(self)\n",
    "        pred = self.model_.predict(X)\n",
    "        return pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d718113d-8d02-4591-abcf-8fa61a410d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84786e80-9a03-42da-b266-6252859c18c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f6e7c7-0dcd-4b98-b7fc-88ed9994d0f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010f43d9-2c0c-4d99-ab28-e25934c70210",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dddex",
   "language": "python",
   "name": "dddex"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
