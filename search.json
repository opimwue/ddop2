[
  {
    "objectID": "loaddatasets.html",
    "href": "loaddatasets.html",
    "title": "Load Datasets",
    "section": "",
    "text": "/opt/hostedtoolcache/Python/3.9.17/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: potentially wrong underline length... \nExamples \n--------- in \nLoad and return the YAZ dataset\n...\n  else: warn(msg)\n\n\n\n\n load_yaz (include_date=False, one_hot_encoding=False,\n           label_encoding=False, return_X_y=False)\n\nLoad and return the YAZ dataset\nYaz is a fast casual restaurant in Stuttgart providing good service and food at short waiting times. The dataset contains the demand for the main ingredients at YAZ. Moreover, it stores a number of demand features. A description of targets and features is given below.\nDataset Characteristics:\n:Number of Instances: 765\n\n:Number of Targets: 7\n\n:Number of Features: 12\n\n:Target Information:\n    - 'calamari' the demand for calamari\n    - 'fish' the demand for fish\n    - 'shrimp' the demand for shrimps\n    - 'chicken' the demand for chicken\n    - 'koefte' the demand for koefte\n    - 'lamb' the demand for lamb\n    - 'steak' the demand for steak\n\n:Feature Information:\n    - 'date' the date,\n    - 'weekday' the day of the week,\n    - 'month' the month of the year,\n    - 'year' the year,\n    - 'is_holiday' whether or not it is a national holiday,\n    - 'is_closed' whether or not the restaurant is closed,\n    - 'weekend' whether or not it is weekend,\n    - 'wind' the wind force,\n    - 'clouds' the cloudiness degree,\n    - 'rain' the amount of rain,\n    - 'sunshine' the sunshine hours,\n    - 'temperature' the outdoor temperature,\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ninclude_date\nbool\nFalse\nWhether to include the demand date\n\n\none_hot_encoding\nbool\nFalse\nWhether to one hot encode categorical features\n\n\nlabel_encoding\nbool\nFalse\nWhether to convert categorical columns (weekday, month, year) to continuous.Will only be applied if one_hot_encoding=False\n\n\nreturn_X_y\nbool\nFalse\nIf True, returns (data, target) instead of a Bunch object.See below for more information about the data and target object.\n\n\nReturns\nsklearn Bunch\n\nDictionary-like object, with the following attributes.data : Pandas DataFrame of shape (765, n_features) The data matrix.target: Pandas DataFrame of shape (765, n_targets) The target values.n_features: int The number of features includedn_targets: int The number of target variables includedDESCR: str The full description of the dataset.data_filename: str The path to the location of the data.target_filename: str The path to the location of the target."
  },
  {
    "objectID": "loaddatasets.html#load-yaz",
    "href": "loaddatasets.html#load-yaz",
    "title": "Load Datasets",
    "section": "",
    "text": "/opt/hostedtoolcache/Python/3.9.17/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: potentially wrong underline length... \nExamples \n--------- in \nLoad and return the YAZ dataset\n...\n  else: warn(msg)\n\n\n\n\n load_yaz (include_date=False, one_hot_encoding=False,\n           label_encoding=False, return_X_y=False)\n\nLoad and return the YAZ dataset\nYaz is a fast casual restaurant in Stuttgart providing good service and food at short waiting times. The dataset contains the demand for the main ingredients at YAZ. Moreover, it stores a number of demand features. A description of targets and features is given below.\nDataset Characteristics:\n:Number of Instances: 765\n\n:Number of Targets: 7\n\n:Number of Features: 12\n\n:Target Information:\n    - 'calamari' the demand for calamari\n    - 'fish' the demand for fish\n    - 'shrimp' the demand for shrimps\n    - 'chicken' the demand for chicken\n    - 'koefte' the demand for koefte\n    - 'lamb' the demand for lamb\n    - 'steak' the demand for steak\n\n:Feature Information:\n    - 'date' the date,\n    - 'weekday' the day of the week,\n    - 'month' the month of the year,\n    - 'year' the year,\n    - 'is_holiday' whether or not it is a national holiday,\n    - 'is_closed' whether or not the restaurant is closed,\n    - 'weekend' whether or not it is weekend,\n    - 'wind' the wind force,\n    - 'clouds' the cloudiness degree,\n    - 'rain' the amount of rain,\n    - 'sunshine' the sunshine hours,\n    - 'temperature' the outdoor temperature,\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ninclude_date\nbool\nFalse\nWhether to include the demand date\n\n\none_hot_encoding\nbool\nFalse\nWhether to one hot encode categorical features\n\n\nlabel_encoding\nbool\nFalse\nWhether to convert categorical columns (weekday, month, year) to continuous.Will only be applied if one_hot_encoding=False\n\n\nreturn_X_y\nbool\nFalse\nIf True, returns (data, target) instead of a Bunch object.See below for more information about the data and target object.\n\n\nReturns\nsklearn Bunch\n\nDictionary-like object, with the following attributes.data : Pandas DataFrame of shape (765, n_features) The data matrix.target: Pandas DataFrame of shape (765, n_targets) The target values.n_features: int The number of features includedn_targets: int The number of target variables includedDESCR: str The full description of the dataset.data_filename: str The path to the location of the data.target_filename: str The path to the location of the target."
  },
  {
    "objectID": "loaddatasets.html#load-bakery",
    "href": "loaddatasets.html#load-bakery",
    "title": "Load Datasets",
    "section": "Load Bakery",
    "text": "Load Bakery\n/opt/hostedtoolcache/Python/3.9.17/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: potentially wrong underline length... \nExamples \n---------- in \nLoad and return the bakery dataset\n...\n  else: warn(msg)\n\n\nload_bakery\n\n load_bakery (include_date=False, one_hot_encoding=False,\n              label_encoding=False, return_X_y=False)\n\nLoad and return the bakery dataset\nThe bakery dataset contains the demand for a number of products from different stores. Moreover, it stores a number of demand features. A description of targets and features is given below.\nDataset Characteristics:\n:Number of Instances: 127575\n\n:Number of Targets: 1\n\n:Number of Features: 13\n\n:Target Information:\n    - 'demand' the corresponding demand observation\n\n:Feature Information:\n    - 'date' the date\n    - 'weekday' the day of the week,\n    - 'month' the month of the year,\n    - 'year' the year,\n    - 'is_holiday' whether or not it is a national holiday,\n    - 'is_holiday_next2days' whether or not it is a national holiday in the next two days,\n    - 'is_schoolholiday' whether or not it is a school holiday,\n    - 'store' the store id,\n    - 'product' the product id,\n    - 'rain' the amount of rain,\n    - 'temperature' the average temperature in °C,\n    - 'promotion_currentweek' whether or not there is a promotion this week\n    - 'promotion_lastweek' whether there was a promotion last week\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ninclude_date\nbool\nFalse\nWhether to include the demand date\n\n\none_hot_encoding\nbool\nFalse\nWhether to one hot encode categorical features\n\n\nlabel_encoding\nbool\nFalse\nWhether to convert categorical columns (weekday, month, year) to continuous.Will only be applied if one_hot_encoding=False\n\n\nreturn_X_y\nbool\nFalse\nIf True, returns (data, target) instead of a Bunch object.See below for more information about the data and target object.\n\n\nReturns\nsklearn Bunch\n\nDictionary-like object, with the following attributes.data : Pandas DataFrame of shape (127575, n_features) The data matrix.target: Pandas DataFrame of shape (127575, n_targets) The target values.n_features: int The number of features includedn_targets: int The number of target variables includedDESCR: str The full description of the dataset.data_filename: str The path to the location of the data.target_filename: str The path to the location of the target."
  },
  {
    "objectID": "loaddatasets.html#load-sid",
    "href": "loaddatasets.html#load-sid",
    "title": "Load Datasets",
    "section": "Load SID",
    "text": "Load SID\n\n\nload_SID\n\n load_SID (include_date=False, one_hot_encoding=False,\n           label_encoding=False, return_X_y=False)\n\nLoad and return the store item demand dataset.\nDataset Characteristics:\n:Number of Instances: 887284\n\n:Number of Targets: 1\n\n:Number of Features: 6\n\n:Target Information:\n    - 'demand' the corresponding demand observation\n\n:Feature Information:\n    - 'date' the date\n    - 'weekday' the day of the week,\n    - 'month' the month of the year,\n    - 'year' the year,\n    - 'store' the store id,\n    - 'item' the item id"
  },
  {
    "objectID": "loaddatasets.html#parameters",
    "href": "loaddatasets.html#parameters",
    "title": "Load Datasets",
    "section": "Parameters",
    "text": "Parameters\ninclude_date : bool, default=False Whether to include the demand date one_hot_encoding : bool, default=False Whether to one hot encode categorical features label_encoding : bool, default=False Whether to convert categorical columns (weekday, month, year) to continuous. Will only be applied if one_hot_encoding=False return_X_y : bool, default=False. If True, returns (data, target) instead of a Bunch object. See below for more information about the data and target object.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ninclude_date\nbool\nFalse\n\n\n\none_hot_encoding\nbool\nFalse\n\n\n\nlabel_encoding\nbool\nFalse\n\n\n\nreturn_X_y\nbool\nFalse\n\n\n\nReturns\nsklearn Bunch\n\nDictionary-like object, with the following attributes.data : Pandas DataFrame of shape (887284, n_features) The data matrix.target: Pandas DataFrame of shape (887284, n_targets) The target values.n_features: int The number of features includedn_targets: int The number of target variables includedDESCR: str The full description of the dataset.data_filename: str The path to the location of the data.target_filename: str The path to the location of the target."
  },
  {
    "objectID": "costs.html#pairwise-costs",
    "href": "costs.html#pairwise-costs",
    "title": "Costs",
    "section": "Pairwise Costs",
    "text": "Pairwise Costs\n\n\npairwise_costs\n\n pairwise_costs (y_true, y_pred, cu, co)\n\nCompute pairwise costs based on the the difference between y_true and y_pred and the given underage and overage costs.\n\n\n\n\nType\nDetails\n\n\n\n\ny_true\narray-like\nThe true values\n\n\ny_pred\narray-like\nThe predicted vales\n\n\ncu\nint or float\nthe underage costs per unit.\n\n\nco\nint or float\nthe overage costs per unit.\n\n\nReturns\nndarray of shape (n_samples, n_outputs)"
  },
  {
    "objectID": "costs.html#total-costs",
    "href": "costs.html#total-costs",
    "title": "Costs",
    "section": "Total Costs",
    "text": "Total Costs\n\n\ntotal_costs\n\n total_costs (y_true, y_pred, cu, co, multioutput='cumulated')\n\nCompute total costs based on the the difference between y_true and y_pred and the given underage and overage costs.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ny_true\narray-like\n\nThe true values\n\n\ny_pred\narray-like\n\nThe predicted vales\n\n\ncu\nint or float\n\nthe underage costs per unit.\n\n\nco\nint or float\n\nthe overage costs per unit.\n\n\nmultioutput\nstr\ncumulated"
  },
  {
    "objectID": "costs.html#average-costs",
    "href": "costs.html#average-costs",
    "title": "Costs",
    "section": "Average Costs",
    "text": "Average Costs\n\n\naverage_costs\n\n average_costs (y_true, y_pred, cu, co, multioutput='uniform_average')\n\nCompute average costs based on the the difference between y_true and y_pred and the given underage and overage costs.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ny_true\narray-like\n\nThe true values\n\n\ny_pred\narray-like\n\nThe predicted vales\n\n\ncu\nint or float\n\nthe underage costs per unit.\n\n\nco\nint or float\n\nthe overage costs per unit.\n\n\nmultioutput\nstr\nuniform_average\n\n\n\nReturns\nfloat or ndarray of floats\n\nThe average costs. If multioutput is ‘raw_values’, then the average costs are returned for eachoutput separately. If multioutput is ‘uniform_average’, then the average of all output costs isreturned. The average costs are non-negative floating points. The best value is 0.0."
  },
  {
    "objectID": "costs.html#prescriptiveness-score",
    "href": "costs.html#prescriptiveness-score",
    "title": "Costs",
    "section": "Prescriptiveness Score",
    "text": "Prescriptiveness Score\n\n\nprescriptiveness_score\n\n prescriptiveness_score (y_true, y_pred, y_pred_saa, cu, co,\n                         multioutput='uniform_average')\n\nCompute the coefficient of prescriptiveness that is defined as (1 - u/v), where u are the average costs between the true and predicted values (y_true,y_pred), and v are the average costs between the true values and the predictions obtained by SAA (y_pred_saa, y_pred). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse).\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ny_true\narray-like\n\nThe true values\n\n\ny_pred\narray-like\n\nThe predicted vales\n\n\ny_pred_saa\n\n\n\n\n\ncu\nint or float\n\nthe underage costs per unit.\n\n\nco\nint or float\n\nthe overage costs per unit.\n\n\nmultioutput\nstr\nuniform_average\n\n\n\nReturns\nfloat or ndarray of floats\n\nThe prescriptiveness score or ndarray of scores if ‘multioutput’ is‘raw_values’."
  },
  {
    "objectID": "sampleaverageapproximation.html",
    "href": "sampleaverageapproximation.html",
    "title": "Sample Average Approximation",
    "section": "",
    "text": "/opt/hostedtoolcache/Python/3.9.17/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: potentially wrong underline length... \nAttributes \n----------- in \nA sample average approximation model to solve the newsvendor problem\n...\n  else: warn(msg)\n/opt/hostedtoolcache/Python/3.9.17/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section Attributes\n  else: warn(msg)\n\n\n\n\n SampleAverageApproximationNewsvendor (cu=None, co=None)\n\nA sample average approximation model to solve the newsvendor problem\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncu\nNoneType\nNone\nThe underage costs per unit. If None, then underage costs are onefor each target variable\n\n\nco\nNoneType\nNone\nThe overage costs per unit. If None, then overage costs are onefor each target variable"
  },
  {
    "objectID": "sampleaverageapproximation.html#sample-average-approximation-newsvendor-class",
    "href": "sampleaverageapproximation.html#sample-average-approximation-newsvendor-class",
    "title": "Sample Average Approximation",
    "section": "",
    "text": "/opt/hostedtoolcache/Python/3.9.17/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: potentially wrong underline length... \nAttributes \n----------- in \nA sample average approximation model to solve the newsvendor problem\n...\n  else: warn(msg)\n/opt/hostedtoolcache/Python/3.9.17/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section Attributes\n  else: warn(msg)\n\n\n\n\n SampleAverageApproximationNewsvendor (cu=None, co=None)\n\nA sample average approximation model to solve the newsvendor problem\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncu\nNoneType\nNone\nThe underage costs per unit. If None, then underage costs are onefor each target variable\n\n\nco\nNoneType\nNone\nThe overage costs per unit. If None, then overage costs are onefor each target variable"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to ddop",
    "section": "",
    "text": "ddop is a Python library for data-driven operations management. The goal of ddop is to provide well-established data-driven operations management tools within a programming environment that is accessible and easy to use even for non-experts. At the current state ddop contains well known data-driven newsvendor models, a set of performance metrics that can be used for model evaluation and selection, as well as datasets that are useful to quickly illustrate the behavior of the various algorithms implemented in ddop or as benchmark for testing new models. Through its consistent and easy-to-use interface one can run and compare provided models with only a few lines of code."
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "Welcome to ddop",
    "section": "Install",
    "text": "Install\nddop is available via PyPI using:\npip install ddop2\nThe installation of this package requires the following dependencies:\n\nnumpy==1.18.2\nscipy==1.4.1\npandas==1.1.4\nstatsmodels==0.11.1\nscikit-learn==0.23.0\ntensorflow==2.4.1\npulp==2.0\nmpmath\n\nNote: The package is actively developed, and conflicts with other packages may occur during installation. To avoid any installation conflicts, we recommend installing the package in an empty environment with the above-mentioned dependencies."
  },
  {
    "objectID": "index.html#quickstart",
    "href": "index.html#quickstart",
    "title": "Welcome to ddop",
    "section": "Quickstart",
    "text": "Quickstart\nddop provides a varity of newsvendor models. The following example shows how to use one of these models for decision making. It assumes a very basic knowledge of data-driven operations management practices.\nAs first step we initialize the model we want to use. In this example RandomForestWeightedNewsvendor.\n\nfrom ddop2.newsvendor import RandomForestWeightedNewsvendor\nrf_nv = RandomForestWeightedNewsvendor(cu=2, co=1)\n\n2023-08-09 22:10:47.225307: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-08-09 22:10:48.239997: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n\n\nA model can take a set of parameters, each describing the model or the optimization problem it tries to solve. Here we set the underage costs cu to 2 and the overage costs co to 1.\nAs next step we load the Yaz Dataset and split it into train and test set.\n\nfrom ddop2.datasets import load_yaz\nfrom sklearn.model_selection import train_test_split\nX, y = load_yaz(one_hot_encoding=True, return_X_y=True)\nX_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False, random_state=0)\n\nAfter the model is initialized, the fit method can be used to learn a decision model from the training data X_train, y_train.\n\nrf_nv.fit(X_train, y_train)\n\nRandomForestWeightedNewsvendor(co=1, cu=2)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomForestWeightedNewsvendorRandomForestWeightedNewsvendor(co=1, cu=2)\n\n\nWe can then use the predict method to make a decision for new data samples.\n\nrf_nv.predict(X_test)\n\narray([[ 5,  4, 14, ..., 23, 35, 22],\n       [ 6,  6, 11, ..., 26, 37, 23],\n       [ 8,  8, 16, ..., 35, 55, 40],\n       ...,\n       [ 5,  6, 12, ..., 23, 41, 25],\n       [ 6,  6, 13, ..., 24, 41, 32],\n       [ 8,  9, 15, ..., 34, 57, 42]])\n\n\nTo get a representation of the model’s decision quality we can use the score function, which takes as input X_test and y_test. The score function makes a decision for each sample in X_test and calculates the negated average costs with respect to the true values y_test and the overage and underage costs.\n\nrf_nv.score(X_test, y_test)\n\n-6.859375000000001"
  },
  {
    "objectID": "weightednewsvendor.html",
    "href": "weightednewsvendor.html",
    "title": "Weighted Newsvendor",
    "section": "",
    "text": "BaseWeightedNewsvendor (cu=None, co=None)\n\nBase class for weighted newsvendor. Warning: This class should not be used directly. Use derived classes instead."
  },
  {
    "objectID": "weightednewsvendor.html#base-weighted-newsvendor-class",
    "href": "weightednewsvendor.html#base-weighted-newsvendor-class",
    "title": "Weighted Newsvendor",
    "section": "",
    "text": "BaseWeightedNewsvendor (cu=None, co=None)\n\nBase class for weighted newsvendor. Warning: This class should not be used directly. Use derived classes instead."
  },
  {
    "objectID": "weightednewsvendor.html#decision-tree-weighted-newsvendor-class",
    "href": "weightednewsvendor.html#decision-tree-weighted-newsvendor-class",
    "title": "Weighted Newsvendor",
    "section": "Decision Tree Weighted Newsvendor Class",
    "text": "Decision Tree Weighted Newsvendor Class\n/opt/hostedtoolcache/Python/3.9.17/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: potentially wrong underline length... \nAttributes \n--------- in \nA decision tree weighted SAA model to solve the newsvendor problem.\n...\n  else: warn(msg)\n/opt/hostedtoolcache/Python/3.9.17/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section Notes\n  else: warn(msg)\n/opt/hostedtoolcache/Python/3.9.17/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section References\n  else: warn(msg)\n/opt/hostedtoolcache/Python/3.9.17/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section Examples\n  else: warn(msg)\n\n\nDecisionTreeWeightedNewsvendor\n\n DecisionTreeWeightedNewsvendor (cu=None, co=None, criterion='mse',\n                                 splitter='best', max_depth=None,\n                                 min_samples_split=2, min_samples_leaf=1,\n                                 min_weight_fraction_leaf=0.0,\n                                 max_features=None, random_state=None,\n                                 max_leaf_nodes=None,\n                                 min_impurity_decrease=0.0, ccp_alpha=0.0)\n\nA decision tree weighted SAA model to solve the newsvendor problem.\nThis class implements the approach described in [5] with a weight function based on decision tree regression. To build the tree the DecisionTreeRegressor from scikit-learn is used [6].\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncu\nNoneType\nNone\nThe underage costs per unit. If None, then underage costs are onefor each target variable\n\n\nco\nNoneType\nNone\nThe overage costs per unit. If None, then overage costs are onefor each target variable\n\n\ncriterion\nstr\nmse\nThe function to measure the quality of a split. Supported criteriaare “mse” for the mean squared error, which is equal to variancereduction as feature selection criterion and minimizes the L2 lossusing the mean of each terminal node, “friedman_mse”, which uses meansquared error with Friedman’s improvement score for potential splits,and “mae” for the mean absolute error, which minimizes the L1 lossusing the median of each terminal node.\n\n\nsplitter\nstr\nbest\nThe strategy used to choose the split at each node. Supportedstrategies are “best” to choose the best split and “random” to choosethe best random split.\n\n\nmax_depth\nNoneType\nNone\nThe maximum depth of the tree. If None, then nodes are expanded untilall leaves are pure or until all leaves contain less thanmin_samples_split samples.\n\n\nmin_samples_split\nint\n2\nThe minimum number of samples required to split an internal node:- If int, then consider min_samples_split as the minimum number.- If float, then min_samples_split is a fraction and ceil(min_samples_split * n_samples) are the minimum number of samples for each split.\n\n\nmin_samples_leaf\nint\n1\nThe minimum number of samples required to be at a leaf node.A split point at any depth will only be considered if it leaves atleast min_samples_leaf training samples in each of the left andright branches. This may have the effect of smoothing the model,especially in regression.- If int, then consider min_samples_leaf as the minimum number.- If float, then min_samples_leaf is a fraction and ceil(min_samples_leaf * n_samples) are the minimum number of samples for each node.\n\n\nmin_weight_fraction_leaf\nfloat\n0.0\nThe minimum weighted fraction of the sum total of weights (of allthe input samples) required to be at a leaf node. Samples haveequal weight when sample_weight is not provided.\n\n\nmax_features\nNoneType\nNone\nThe number of features to consider when looking for the best split:- If int, then consider max_features features at each split.- If float, then max_features is a fraction and int(max_features * n_features) features are considered at each split.- If “auto”, then max_features=n_features.- If “sqrt”, then max_features=sqrt(n_features).- If “log2”, then max_features=log2(n_features).- If None, then max_features=n_features.Note: the search for a split does not stop until at least onevalid partition of the node samples is found, even if it requires toeffectively inspect more than max_features features.\n\n\nrandom_state\nNoneType\nNone\nControls the randomness of the estimator. The features are alwaysrandomly permuted at each split, even if splitter is set to\"best\". When max_features &lt; n_features, the algorithm willselect max_features at random at each split before finding the bestsplit among them. But the best found split may vary across differentruns, even if max_features=n_features. That is the case, if theimprovement of the criterion is identical for several splits and onesplit has to be selected at random. To obtain a deterministic behaviourduring fitting, random_state has to be fixed to an integer.See :term:Glossary &lt;random_state&gt; for details.\n\n\nmax_leaf_nodes\nNoneType\nNone\nGrow a tree with max_leaf_nodes in best-first fashion.Best nodes are defined as relative reduction in impurity.If None then unlimited number of leaf nodes.\n\n\nmin_impurity_decrease\nfloat\n0.0\nA node will be split if this split induces a decrease of the impuritygreater than or equal to this value.The weighted impurity decrease equation is the following:: N_t / N * (impurity - N_t_R / N_t * right_impurity - N_t_L / N_t * left_impurity)where N is the total number of samples, N_t is the number ofsamples at the current node, N_t_L is the number of samples in theleft child, and N_t_R is the number of samples in the right child.N, N_t, N_t_R and N_t_L all refer to the weighted sum,if sample_weight is passed.\n\n\nccp_alpha\nfloat\n0.0\nComplexity parameter used for Minimal Cost-Complexity Pruning. Thesubtree with the largest cost complexity that is smaller thanccp_alpha will be chosen. By default, no pruning is performed. See:ref:minimal_cost_complexity_pruning for details."
  },
  {
    "objectID": "weightednewsvendor.html#random-forest-weighted-newsvendor-class",
    "href": "weightednewsvendor.html#random-forest-weighted-newsvendor-class",
    "title": "Weighted Newsvendor",
    "section": "Random Forest Weighted Newsvendor Class",
    "text": "Random Forest Weighted Newsvendor Class\n/opt/hostedtoolcache/Python/3.9.17/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: potentially wrong underline length... \nAttributes \n--------- in \nA random forest weighted SAA model to solve the newsvendor problem.\n...\n  else: warn(msg)\n\n\nRandomForestWeightedNewsvendor\n\n RandomForestWeightedNewsvendor (cu=None, co=None,\n                                 criterion='squared_error',\n                                 n_estimators=100, max_depth=None,\n                                 min_samples_split=2, min_samples_leaf=1,\n                                 min_weight_fraction_leaf=0.0,\n                                 max_features=1, max_leaf_nodes=None,\n                                 min_impurity_decrease=0.0,\n                                 bootstrap=True, oob_score=False,\n                                 n_jobs=None, random_state=None,\n                                 verbose=0, warm_start=False,\n                                 ccp_alpha=0.0, max_samples=None,\n                                 weight_function='w1')\n\nA random forest weighted SAA model to solve the newsvendor problem.\nThis class implements the approach described in [3] with a weight function based on random forest regression. To build the random forest the RandomForestRegressor from scikit-learn is used [4].\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncu\nNoneType\nNone\nThe underage costs per unit. If None, then underage costs are onefor each target variable\n\n\nco\nNoneType\nNone\nThe overage costs per unit. If None, then overage costs are onefor each target variable\n\n\ncriterion\nstr\nsquared_error\n\n\n\nn_estimators\nint\n100\nThe number of trees in the forest.\n\n\nmax_depth\nNoneType\nNone\nThe maximum depth of the tree. If None, then nodes are expanded untilall leaves are pure or until all leaves contain less thanmin_samples_split samples.\n\n\nmin_samples_split\nint\n2\nThe minimum number of samples required to split an internal node:- If int, then consider min_samples_split as the minimum number.- If float, then min_samples_split is a fraction and ceil(min_samples_split * n_samples) are the minimum number of samples for each split.\n\n\nmin_samples_leaf\nint\n1\nThe minimum number of samples required to be at a leaf node.A split point at any depth will only be considered if it leaves atleast min_samples_leaf training samples in each of the left andright branches. This may have the effect of smoothing the model,especially in regression.- If int, then consider min_samples_leaf as the minimum number.- If float, then min_samples_leaf is a fraction and ceil(min_samples_leaf * n_samples) are the minimum number of samples for each node.\n\n\nmin_weight_fraction_leaf\nfloat\n0.0\nThe minimum weighted fraction of the sum total of weights (of allthe input samples) required to be at a leaf node. Samples haveequal weight when sample_weight is not provided.\n\n\nmax_features\nint\n1\nThe number of features to consider when looking for the best split:- If int, then consider max_features features at each split.- If float, then max_features is a fraction and int(max_features * n_features) features are considered at each split.- If “auto”, then max_features=n_features.- If “sqrt”, then max_features=sqrt(n_features).- If “log2”, then max_features=log2(n_features).- If None, then max_features=n_features.Note: the search for a split does not stop until at least onevalid partition of the node samples is found, even if it requires toeffectively inspect more than max_features features.\n\n\nmax_leaf_nodes\nNoneType\nNone\nGrow trees with max_leaf_nodes in best-first fashion.Best nodes are defined as relative reduction in impurity.If None then unlimited number of leaf nodes.\n\n\nmin_impurity_decrease\nfloat\n0.0\nA node will be split if this split induces a decrease of the impuritygreater than or equal to this value.The weighted impurity decrease equation is the following:: N_t / N * (impurity - N_t_R / N_t * right_impurity - N_t_L / N_t * left_impurity)where N is the total number of samples, N_t is the number ofsamples at the current node, N_t_L is the number of samples in theleft child, and N_t_R is the number of samples in the right child.N, N_t, N_t_R and N_t_L all refer to the weighted sum,if sample_weight is passed.\n\n\nbootstrap\nbool\nTrue\nWhether bootstrap samples are used when building trees. If False, thewhole dataset is used to build each tree.\n\n\noob_score\nbool\nFalse\nwhether to use out-of-bag samples to estimatethe R^2 on unseen data.\n\n\nn_jobs\nNoneType\nNone\nThe number of jobs to run in parallel. :meth:fit, :meth:predict,:meth:decision_path and :meth:apply are all parallelized over thetrees. None means 1 unless in a :obj:joblib.parallel_backendcontext. -1 means using all processors.\n\n\nrandom_state\nNoneType\nNone\nControls both the randomness of the bootstrapping of the samples usedwhen building trees (if bootstrap=True) and the sampling of thefeatures to consider when looking for the best split at each node(if max_features &lt; n_features).\n\n\nverbose\nint\n0\nControls the verbosity when fitting and predicting.\n\n\nwarm_start\nbool\nFalse\nWhen set to True, reuse the solution of the previous call to fitand add more estimators to the ensemble, otherwise, just fit a wholenew forest.\n\n\nccp_alpha\nfloat\n0.0\nComplexity parameter used for Minimal Cost-Complexity Pruning. Thesubtree with the largest cost complexity that is smaller thanccp_alpha will be chosen. By default, no pruning is performed.\n\n\nmax_samples\nNoneType\nNone\nIf bootstrap is True, the number of samples to draw from Xto train each base estimator.- If None (default), then draw X.shape[0] samples.- If int, then draw max_samples samples.- If float, then draw max_samples * X.shape[0] samples. Thus, max_samples should be in the interval (0, 1).\n\n\nweight_function\nstr\nw1\nIndicates how to determine the sample weights. If set to “w1” the weightfunction corresponds to the one described in [3]. If set to “w2” theweight function described in [5] will be used."
  },
  {
    "objectID": "weightednewsvendor.html#k-nearest-neighbors-weighted-newsvendor-class",
    "href": "weightednewsvendor.html#k-nearest-neighbors-weighted-newsvendor-class",
    "title": "Weighted Newsvendor",
    "section": "K-Nearest-Neighbors Weighted Newsvendor Class",
    "text": "K-Nearest-Neighbors Weighted Newsvendor Class\n/opt/hostedtoolcache/Python/3.9.17/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: potentially wrong underline length... \nAttributes \n--------- in \nA k-nearest-neighbor weighted SAA model to solve the newsvendor problem\n...\n  else: warn(msg)\n\n\nKNeighborsWeightedNewsvendor\n\n KNeighborsWeightedNewsvendor (cu=None, co=None, n_neighbors=5,\n                               radius=1.0, algorithm='auto', leaf_size=30,\n                               metric='minkowski', p=2,\n                               metric_params=None, n_jobs=None)\n\nA k-nearest-neighbor weighted SAA model to solve the newsvendor problem\nThis class implements the approach described in [3] with a weight function based k-nearest-neighbor regression. To determine the k-nearest-neighbors NearestNeighbors from scikit-learn is used [4].\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncu\nNoneType\nNone\nThe underage costs per unit. If None, then underage costs are onefor each target variable\n\n\nco\nNoneType\nNone\nThe overage costs per unit. If None, then overage costs are onefor each target variable\n\n\nn_neighbors\nint\n5\nNumber of neighbors to use by default for :meth:kneighbors queries.\n\n\nradius\nfloat\n1.0\nRange of parameter space to use by default for :meth:radius_neighborsqueries.\n\n\nalgorithm\nstr\nauto\nAlgorithm used to compute the nearest neighbors:- ‘ball_tree’ will use :class:BallTree- ‘kd_tree’ will use :class:KDTree- ‘brute’ will use a brute-force search.- ‘auto’ will attempt to decide the most appropriate algorithm based on the values passed to :meth:fit method.Note: fitting on sparse input will override the setting ofthis parameter, using brute force.\n\n\nleaf_size\nint\n30\nLeaf size passed to BallTree or KDTree. This can affect thespeed of the construction and query, as well as the memoryrequired to store the tree. The optimal value depends on thenature of the problem.\n\n\nmetric\nstr\nminkowski\nthe distance metric to use for the tree. The default metric isminkowski, and with p=2 is equivalent to the standard Euclideanmetric. See the documentation of :class:DistanceMetric for alist of available metrics.If metric is “precomputed”, X is assumed to be a distance matrix andmust be square during fit. X may be a :term:sparse graph,in which case only “nonzero” elements may be considered neighbors.\n\n\np\nint\n2\nParameter for the Minkowski metric fromsklearn.metrics.pairwise.pairwise_distances. When p = 1, this isequivalent to using manhattan_distance (l1), and euclidean_distance(l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.\n\n\nmetric_params\nNoneType\nNone\nAdditional keyword arguments for the metric function.\n\n\nn_jobs\nNoneType\nNone\nThe number of parallel jobs to run for neighbors search.None means 1 unless in a :obj:joblib.parallel_backend context.-1 means using all processors."
  },
  {
    "objectID": "weightednewsvendor.html#gaussian-weighted-newsvendor-class",
    "href": "weightednewsvendor.html#gaussian-weighted-newsvendor-class",
    "title": "Weighted Newsvendor",
    "section": "Gaussian Weighted Newsvendor Class",
    "text": "Gaussian Weighted Newsvendor Class\n/opt/hostedtoolcache/Python/3.9.17/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: potentially wrong underline length... \nAttributes \n--------- in \nA gaussian kernel weighted SAA model to solve the newsvendor problem\n...\n  else: warn(msg)\n\n\nGaussianWeightedNewsvendor\n\n GaussianWeightedNewsvendor (cu=None, co=None, kernel_bandwidth=1)\n\nA gaussian kernel weighted SAA model to solve the newsvendor problem\nThis class implements the approach described in [1] with a gaussian kernel weight function.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncu\nNoneType\nNone\nThe underage costs per unit. If None, then underage costs are onefor each target variable\n\n\nco\nNoneType\nNone\nThe overage costs per unit. If None, then overage costs are onefor each target variable\n\n\nkernel_bandwidth\nint\n1"
  },
  {
    "objectID": "linearregressionnewsvendor.html",
    "href": "linearregressionnewsvendor.html",
    "title": "Linear Regression Newsvendor",
    "section": "",
    "text": "/opt/hostedtoolcache/Python/3.9.17/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section Attributes\n  else: warn(msg)\n/opt/hostedtoolcache/Python/3.9.17/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section References\n  else: warn(msg)\n/opt/hostedtoolcache/Python/3.9.17/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section Examples\n  else: warn(msg)\n\n\n\n\n LinearRegressionNewsvendor (cu=None, co=None)\n\nA linear regression model to solve the Newsvendor problem\nThis class implements the approach described in [1].\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncu\nNoneType\nNone\nThe underage costs per unit. If None, then underage costs are onefor each target variable\n\n\nco\nNoneType\nNone\nThe overage costs per unit. If None, then overage costs are onefor each target variable"
  },
  {
    "objectID": "linearregressionnewsvendor.html#linear-regression-newsvendor-class",
    "href": "linearregressionnewsvendor.html#linear-regression-newsvendor-class",
    "title": "Linear Regression Newsvendor",
    "section": "",
    "text": "/opt/hostedtoolcache/Python/3.9.17/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section Attributes\n  else: warn(msg)\n/opt/hostedtoolcache/Python/3.9.17/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section References\n  else: warn(msg)\n/opt/hostedtoolcache/Python/3.9.17/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section Examples\n  else: warn(msg)\n\n\n\n\n LinearRegressionNewsvendor (cu=None, co=None)\n\nA linear regression model to solve the Newsvendor problem\nThis class implements the approach described in [1].\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncu\nNoneType\nNone\nThe underage costs per unit. If None, then underage costs are onefor each target variable\n\n\nco\nNoneType\nNone\nThe overage costs per unit. If None, then overage costs are onefor each target variable"
  },
  {
    "objectID": "scorer.html#make-scorer",
    "href": "scorer.html#make-scorer",
    "title": "Scorer",
    "section": "Make Scorer",
    "text": "Make Scorer\n\n\nmake_scorer\n\n make_scorer (score_func, greater_is_better=True, **kwargs)\n\nMake a scorer from a performance metric or loss function. This factory function wraps scoring functions for use in sklearn.model_selection.GridSearchCV and sklearn.model_selection.cross_val_score. It takes a score function from ddop.metrics, such as ddop.metrics.total_costs, and returns a callable that scores an estimator’s output. The signature of the call is (estimator, X, y) where estimator is the model to be evaluated, X is the data and y is the ground truth labeling.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nscore_func\ncallable\n\nScore function included in ddop.metrics.\n\n\ngreater_is_better\nbool\nTrue\nWhether score_func is a score function (default), meaning high is good,or a loss function, meaning low is good. In the latter case, thescorer object will sign-flip the outcome of the score_func.\n\n\nkwargs\n\n\n\n\n\nReturns\ncallable\n\nCallable object that returns a scalar score; greater is better."
  },
  {
    "objectID": "basenewsvendor.html",
    "href": "basenewsvendor.html",
    "title": "Base Newsvendor Classes",
    "section": "",
    "text": "BaseNewsvendor (cu, co)\n\nBase class for newsvendor."
  },
  {
    "objectID": "basenewsvendor.html#base-newsvendor-class",
    "href": "basenewsvendor.html#base-newsvendor-class",
    "title": "Base Newsvendor Classes",
    "section": "",
    "text": "BaseNewsvendor (cu, co)\n\nBase class for newsvendor."
  },
  {
    "objectID": "basenewsvendor.html#datadrivenmixin-class",
    "href": "basenewsvendor.html#datadrivenmixin-class",
    "title": "Base Newsvendor Classes",
    "section": "DataDrivenMixin Class",
    "text": "DataDrivenMixin Class\n\n\nDataDrivenMixin\n\n DataDrivenMixin ()\n\nInitialize self. See help(type(self)) for accurate signature."
  },
  {
    "objectID": "basenewsvendor.html#classicmixin-class",
    "href": "basenewsvendor.html#classicmixin-class",
    "title": "Base Newsvendor Classes",
    "section": "ClassicMixin Class",
    "text": "ClassicMixin Class\n\n\nClassicMixin\n\n ClassicMixin ()\n\nInitialize self. See help(type(self)) for accurate signature."
  },
  {
    "objectID": "test_costs.html",
    "href": "test_costs.html",
    "title": "Tests",
    "section": "",
    "text": "import unittest\nfrom ddop2.metrics._costs import pairwise_costs, average_costs, total_costs\nfrom numpy.testing import assert_array_equal\n\n2023-08-09 22:13:41.459376: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-08-09 22:13:43.196668: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT"
  },
  {
    "objectID": "test_costs.html#old-unit-tests",
    "href": "test_costs.html#old-unit-tests",
    "title": "Tests",
    "section": "Old Unit Tests",
    "text": "Old Unit Tests\n\nCheck cost parameters\n\nclass TestCosts(unittest.TestCase):\n\n    def test_pairwise_costs(self):\n        assert_array_equal(pairwise_costs([1], [10], 1, 2), [[18]])\n        assert_array_equal(pairwise_costs([10], [1], 2, 1), [[18]])\n        assert_array_equal(pairwise_costs([1, 10], [2, 5], 1, 1), [[1], [5]])\n        assert_array_equal(pairwise_costs([1, 10], [2, 5], 2, 1), [[1], [10]])\n        assert_array_equal(pairwise_costs([1, 10], [2, 5], 1, 2), [[2], [5]])\n        # multioutput\n        assert_array_equal(pairwise_costs([[1, 10], [2, 5]], [[2, 4], [1, 8]], 1, 1), [[1, 6], [1, 3]])\n        # multioutput and differend cost coefficients\n        assert_array_equal(pairwise_costs([[1, 10], [2, 5]], [[2, 4], [1, 8]], [1, 1], [1, 2]), [[1, 6], [1, 6]])\n\n    def test_total_costs(self):\n        assert_array_equal(total_costs([1], [10], 1, 2), 18)\n        assert_array_equal(total_costs([10], [1], 2, 1), 18)\n        assert_array_equal(total_costs([1, 10], [2, 5], 1, 1), 6)\n        assert_array_equal(total_costs([1, 10], [2, 5], 2, 1), 11)\n        assert_array_equal(total_costs([1, 10], [2, 5], 1, 2), 7)\n        # multioutput\n        assert_array_equal(total_costs([[1, 10], [2, 5]], [[2, 4], [1, 8]], 1, 1, multioutput=\"cumulated\"), 11)\n        assert_array_equal(total_costs([[1, 10], [2, 5]], [[2, 4], [1, 8]], 1, 1, multioutput=\"raw_values\"), [2, 9])\n        # multioutput and differend cost coefficients\n        assert_array_equal(total_costs([[1, 10], [2, 5]], [[2, 4], [1, 8]], [1, 1], [1, 2], multioutput=\"cumulated\"),\n                           14)\n        assert_array_equal(total_costs([[1, 10], [2, 5]], [[2, 4], [1, 8]], [1, 1], [1, 2], multioutput=\"raw_values\"),\n                           [2, 12])\n\n    def test_average_costs(self):\n        assert_array_equal(average_costs([1], [10], 1, 2), 18)\n        assert_array_equal(average_costs([10], [1], 2, 1), 18)\n        assert_array_equal(average_costs([1, 10], [2, 5], 1, 1), 3)\n        assert_array_equal(average_costs([1, 10], [2, 5], 2, 1), 5.5)\n        assert_array_equal(average_costs([1, 10], [2, 5], 1, 2), 3.5)\n        # multioutput\n        assert_array_equal(average_costs([[1, 10], [2, 5]], [[2, 4], [1, 8]], 1, 1, multioutput=\"uniform_average\"), 2.75)\n        assert_array_equal(average_costs([[1, 10], [2, 5]], [[2, 4], [1, 8]], 1, 1, multioutput=\"raw_values\"), [1, 4.5])\n        # multioutput and differend cost coefficients\n        assert_array_equal(average_costs([[1, 10], [2, 5]], [[2, 4], [1, 8]], [1, 1], [1, 2], multioutput=\"uniform_average\"),\n                           3.5)\n        assert_array_equal(average_costs([[1, 10], [2, 5]], [[2, 4], [1, 8]], [1, 1], [1, 2], multioutput=\"raw_values\"),\n                           [1, 6])\n\n\n# if __name__ == '__main__':\n#     unittest.main()"
  },
  {
    "objectID": "test_costs.html#new-unit-tests",
    "href": "test_costs.html#new-unit-tests",
    "title": "Tests",
    "section": "New Unit Tests",
    "text": "New Unit Tests\nAs we are using nbdev, we don’t need to write unit tests directly.\n\nTest Pairwise Costs\n\nassert_array_equal(pairwise_costs([1], [10], 1, 2), [[18]])\nassert_array_equal(pairwise_costs([10], [1], 2, 1), [[18]])\nassert_array_equal(pairwise_costs([1, 10], [2, 5], 1, 1), [[1], [5]])\nassert_array_equal(pairwise_costs([1, 10], [2, 5], 2, 1), [[1], [10]])\nassert_array_equal(pairwise_costs([1, 10], [2, 5], 1, 2), [[2], [5]])\n\n# multioutput\nassert_array_equal(pairwise_costs([[1, 10], [2, 5]], [[2, 4], [1, 8]], 1, 1), [[1, 6], [1, 3]])\n\n# multioutput and differend cost coefficients\nassert_array_equal(pairwise_costs([[1, 10], [2, 5]], [[2, 4], [1, 8]], [1, 1], [1, 2]), [[1, 6], [1, 6]])\n\n\n\nTest Total Costs\n\nassert_array_equal(total_costs([1], [10], 1, 2), 18)\nassert_array_equal(total_costs([10], [1], 2, 1), 18)\nassert_array_equal(total_costs([1, 10], [2, 5], 1, 1), 6)\nassert_array_equal(total_costs([1, 10], [2, 5], 2, 1), 11)\nassert_array_equal(total_costs([1, 10], [2, 5], 1, 2), 7)\n\n# multioutput\nassert_array_equal(total_costs([[1, 10], [2, 5]], [[2, 4], [1, 8]], 1, 1, multioutput=\"cumulated\"), 11)\nassert_array_equal(total_costs([[1, 10], [2, 5]], [[2, 4], [1, 8]], 1, 1, multioutput=\"raw_values\"), [2, 9])\n\n# multioutput and differend cost coefficients\nassert_array_equal(total_costs([[1, 10], [2, 5]], [[2, 4], [1, 8]], [1, 1], [1, 2], multioutput=\"cumulated\"),\n                   14)\nassert_array_equal(total_costs([[1, 10], [2, 5]], [[2, 4], [1, 8]], [1, 1], [1, 2], multioutput=\"raw_values\"),\n                   [2, 12])\n\n\n\nTest Average Costs\n\nassert_array_equal(average_costs([1], [10], 1, 2), 18)\nassert_array_equal(average_costs([10], [1], 2, 1), 18)\nassert_array_equal(average_costs([1, 10], [2, 5], 1, 1), 3)\nassert_array_equal(average_costs([1, 10], [2, 5], 2, 1), 5.5)\nassert_array_equal(average_costs([1, 10], [2, 5], 1, 2), 3.5)\n# multioutput\nassert_array_equal(average_costs([[1, 10], [2, 5]], [[2, 4], [1, 8]], 1, 1, multioutput=\"uniform_average\"), 2.75)\nassert_array_equal(average_costs([[1, 10], [2, 5]], [[2, 4], [1, 8]], 1, 1, multioutput=\"raw_values\"), [1, 4.5])\n# multioutput and differend cost coefficients\nassert_array_equal(average_costs([[1, 10], [2, 5]], [[2, 4], [1, 8]], [1, 1], [1, 2], multioutput=\"uniform_average\"),\n                   3.5)\nassert_array_equal(average_costs([[1, 10], [2, 5]], [[2, 4], [1, 8]], [1, 1], [1, 2], multioutput=\"raw_values\"),\n                   [1, 6])"
  },
  {
    "objectID": "exponentialsmoothingnewsvendor.html",
    "href": "exponentialsmoothingnewsvendor.html",
    "title": "Exponential Smoothing Newsvendor",
    "section": "",
    "text": "/opt/hostedtoolcache/Python/3.9.17/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section Attributes\n  else: warn(msg)\n/opt/hostedtoolcache/Python/3.9.17/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section Notes\n  else: warn(msg)\n/opt/hostedtoolcache/Python/3.9.17/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section References\n  else: warn(msg)\n/opt/hostedtoolcache/Python/3.9.17/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section Examples\n  else: warn(msg)\n\n\n\n\n ExponentialSmoothingNewsvendor (cu=None, co=None, trend=None,\n                                 damped_trend=False, seasonal=None,\n                                 seasonal_periods=None,\n                                 initialization_method='estimated',\n                                 initial_level=None, initial_trend=None,\n                                 initial_seasonal=None, use_boxcox=False,\n                                 smoothing_level=None,\n                                 smoothing_trend=None,\n                                 smoothing_seasonal=None, optimized=True,\n                                 remove_bias=False, method='L-BFGS-B')\n\nA SEO newsvendor model with exponential smoothing as underlying forecaster\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncu\nNoneType\nNone\nThe underage costs per unit. If None, then underage costs are onefor each target variable\n\n\nco\nNoneType\nNone\nThe overage costs per unit. If None, then overage costs are onefor each target variable\n\n\ntrend\nNoneType\nNone\nType of trend component.\n\n\ndamped_trend\nbool\nFalse\nShould the trend component be damped.\n\n\nseasonal\nNoneType\nNone\nType of seasonal component.\n\n\nseasonal_periods\nNoneType\nNone\nThe number of periods in a complete seasonal cycle, e.g., 4 forquarterly data or 7 for daily data with a weekly cycle.\n\n\ninitialization_method\nstr\nestimated\nMethod for initialize the recursions. One of:* ‘estimated’* ‘heuristic’* ‘legacy-heuristic’* ‘known’If ‘known’ initialization is used, then initial_levelmust be passed, as well as initial_trend and initial_seasonal ifapplicable. Default is ‘estimated’.\n\n\ninitial_level\nNoneType\nNone\nThe initial level component. Required if estimation method is “known”.If set using either “estimated” or “heuristic” this value is used.This allows one or more of the initial values to be set whiledeferring to the heuristic for others or estimating the unsetparameters.\n\n\ninitial_trend\nNoneType\nNone\nThe initial trend component. Required if estimation method is “known”.If set using either “estimated” or “heuristic” this value is used.This allows one or more of the initial values to be set whiledeferring to the heuristic for others or estimating the unsetparameters.\n\n\ninitial_seasonal\nNoneType\nNone\nThe initial seasonal component. An array of length seasonalor length seasonal - 1 (in which case the last initial valueis computed to make the average effect zero). Only used ifinitialization is ‘known’. Required if estimation method is “known”.If set using either “estimated” or “heuristic” this value is used.This allows one or more of the initial values to be set whiledeferring to the heuristic for others or estimating the unsetparameters.\n\n\nuse_boxcox\nbool\nFalse\nShould the Box-Cox transform be applied to the data first? If ‘log’then apply the log. If float then use lambda equal to float.\n\n\nsmoothing_level\nNoneType\nNone\nThe alpha value of the simple exponential smoothing, if the valueis set then this value will be used as the value.\n\n\nsmoothing_trend\nNoneType\nNone\nThe beta value of the Holt’s trend method, if the value isset then this value will be used as the value.\n\n\nsmoothing_seasonal\nNoneType\nNone\nThe gamma value of the holt winters seasonal method, if the valueis set then this value will be used as the value.\n\n\noptimized\nbool\nTrue\nEstimate model parameters by maximizing the log-likelihood\n\n\nremove_bias\nbool\nFalse\nRemove bias from forecast values and fitted values by enforcingthat the average residual is equal to zero.\n\n\nmethod\nstr\nL-BFGS-B\nThe minimizer used. Valid options are “L-BFGS-B” (default), “TNC”,“SLSQP”, “Powell”, “trust-constr”, “basinhopping” (also “bh”) and“least_squares” (also “ls”). basinhopping tries multiple startingvalues in an attempt to find a global minimizer in non-convexproblems, and so is slower than the others."
  },
  {
    "objectID": "exponentialsmoothingnewsvendor.html#exponential-smoothing-newsvendor-class",
    "href": "exponentialsmoothingnewsvendor.html#exponential-smoothing-newsvendor-class",
    "title": "Exponential Smoothing Newsvendor",
    "section": "",
    "text": "/opt/hostedtoolcache/Python/3.9.17/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section Attributes\n  else: warn(msg)\n/opt/hostedtoolcache/Python/3.9.17/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section Notes\n  else: warn(msg)\n/opt/hostedtoolcache/Python/3.9.17/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section References\n  else: warn(msg)\n/opt/hostedtoolcache/Python/3.9.17/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section Examples\n  else: warn(msg)\n\n\n\n\n ExponentialSmoothingNewsvendor (cu=None, co=None, trend=None,\n                                 damped_trend=False, seasonal=None,\n                                 seasonal_periods=None,\n                                 initialization_method='estimated',\n                                 initial_level=None, initial_trend=None,\n                                 initial_seasonal=None, use_boxcox=False,\n                                 smoothing_level=None,\n                                 smoothing_trend=None,\n                                 smoothing_seasonal=None, optimized=True,\n                                 remove_bias=False, method='L-BFGS-B')\n\nA SEO newsvendor model with exponential smoothing as underlying forecaster\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncu\nNoneType\nNone\nThe underage costs per unit. If None, then underage costs are onefor each target variable\n\n\nco\nNoneType\nNone\nThe overage costs per unit. If None, then overage costs are onefor each target variable\n\n\ntrend\nNoneType\nNone\nType of trend component.\n\n\ndamped_trend\nbool\nFalse\nShould the trend component be damped.\n\n\nseasonal\nNoneType\nNone\nType of seasonal component.\n\n\nseasonal_periods\nNoneType\nNone\nThe number of periods in a complete seasonal cycle, e.g., 4 forquarterly data or 7 for daily data with a weekly cycle.\n\n\ninitialization_method\nstr\nestimated\nMethod for initialize the recursions. One of:* ‘estimated’* ‘heuristic’* ‘legacy-heuristic’* ‘known’If ‘known’ initialization is used, then initial_levelmust be passed, as well as initial_trend and initial_seasonal ifapplicable. Default is ‘estimated’.\n\n\ninitial_level\nNoneType\nNone\nThe initial level component. Required if estimation method is “known”.If set using either “estimated” or “heuristic” this value is used.This allows one or more of the initial values to be set whiledeferring to the heuristic for others or estimating the unsetparameters.\n\n\ninitial_trend\nNoneType\nNone\nThe initial trend component. Required if estimation method is “known”.If set using either “estimated” or “heuristic” this value is used.This allows one or more of the initial values to be set whiledeferring to the heuristic for others or estimating the unsetparameters.\n\n\ninitial_seasonal\nNoneType\nNone\nThe initial seasonal component. An array of length seasonalor length seasonal - 1 (in which case the last initial valueis computed to make the average effect zero). Only used ifinitialization is ‘known’. Required if estimation method is “known”.If set using either “estimated” or “heuristic” this value is used.This allows one or more of the initial values to be set whiledeferring to the heuristic for others or estimating the unsetparameters.\n\n\nuse_boxcox\nbool\nFalse\nShould the Box-Cox transform be applied to the data first? If ‘log’then apply the log. If float then use lambda equal to float.\n\n\nsmoothing_level\nNoneType\nNone\nThe alpha value of the simple exponential smoothing, if the valueis set then this value will be used as the value.\n\n\nsmoothing_trend\nNoneType\nNone\nThe beta value of the Holt’s trend method, if the value isset then this value will be used as the value.\n\n\nsmoothing_seasonal\nNoneType\nNone\nThe gamma value of the holt winters seasonal method, if the valueis set then this value will be used as the value.\n\n\noptimized\nbool\nTrue\nEstimate model parameters by maximizing the log-likelihood\n\n\nremove_bias\nbool\nFalse\nRemove bias from forecast values and fitted values by enforcingthat the average residual is equal to zero.\n\n\nmethod\nstr\nL-BFGS-B\nThe minimizer used. Valid options are “L-BFGS-B” (default), “TNC”,“SLSQP”, “Powell”, “trust-constr”, “basinhopping” (also “bh”) and“least_squares” (also “ls”). basinhopping tries multiple startingvalues in an attempt to find a global minimizer in non-convexproblems, and so is slower than the others."
  },
  {
    "objectID": "validation.html",
    "href": "validation.html",
    "title": "Validation",
    "section": "",
    "text": "source\n\n\n\n check_cu_co (cu, co, n_outputs)\n\nValidate under- and overage costs.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ncu\nndarray, shape (n_outputs,)\nValidated underage costs. It is guaranteed to be “C” contiguous.\n\n\nco\nndarray, shape (n_outputs,)\nValidated overage costs. It is guaranteed to be “C” contiguous.\n\n\nn_outputs\nint\nThe number of outputs."
  },
  {
    "objectID": "validation.html#check-cost-parameters",
    "href": "validation.html#check-cost-parameters",
    "title": "Validation",
    "section": "",
    "text": "source\n\n\n\n check_cu_co (cu, co, n_outputs)\n\nValidate under- and overage costs.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ncu\nndarray, shape (n_outputs,)\nValidated underage costs. It is guaranteed to be “C” contiguous.\n\n\nco\nndarray, shape (n_outputs,)\nValidated overage costs. It is guaranteed to be “C” contiguous.\n\n\nn_outputs\nint\nThe number of outputs."
  },
  {
    "objectID": "deeplearningnewsvendor.html",
    "href": "deeplearningnewsvendor.html",
    "title": "Validation",
    "section": "",
    "text": "DeepLearningNewsvendor (cu=None, co=None, neurons=[100, 50],\n                         activations=['relu', 'relu'], optimizer='adam',\n                         epochs=100, random_state=None, verbose=0)\n\nA Deep-Learning model to solve the Newsvendor problem.\nThis class implements the approach described in [1].\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncu\nNoneType\nNone\nThe underage costs per unit. If None, then underage costs are onefor each target variable\n\n\nco\nNoneType\nNone\nThe overage costs per unit. If None, then overage costs are onefor each target variable\n\n\nneurons\nlist\n[100, 50]\nThe ith element represents the number of neurons in the ith hidden layerOnly used when hidden_layers=‘custom’.\n\n\nactivations\nlist\n[‘relu’, ‘relu’]\nThe ith element of the list represents the activation function of the ith layer.Valid activation functions are: ‘elu’, ‘selu’, ‘linear’, ‘tanh’, ‘relu’, ‘softmax’,‘softsign’, ‘softplus’,‘sigmoid’, ‘hard_sigmoid’, ‘exponential’.Only used when hidden_layers=‘custom’.\n\n\noptimizer\nstr\nadam\n\n\n\nepochs\nint\n100\n\n\n\nrandom_state\nNoneType\nNone\n\n\n\nverbose\nint\n0"
  },
  {
    "objectID": "deeplearningnewsvendor.html#check-cost-parameters",
    "href": "deeplearningnewsvendor.html#check-cost-parameters",
    "title": "Validation",
    "section": "",
    "text": "DeepLearningNewsvendor (cu=None, co=None, neurons=[100, 50],\n                         activations=['relu', 'relu'], optimizer='adam',\n                         epochs=100, random_state=None, verbose=0)\n\nA Deep-Learning model to solve the Newsvendor problem.\nThis class implements the approach described in [1].\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncu\nNoneType\nNone\nThe underage costs per unit. If None, then underage costs are onefor each target variable\n\n\nco\nNoneType\nNone\nThe overage costs per unit. If None, then overage costs are onefor each target variable\n\n\nneurons\nlist\n[100, 50]\nThe ith element represents the number of neurons in the ith hidden layerOnly used when hidden_layers=‘custom’.\n\n\nactivations\nlist\n[‘relu’, ‘relu’]\nThe ith element of the list represents the activation function of the ith layer.Valid activation functions are: ‘elu’, ‘selu’, ‘linear’, ‘tanh’, ‘relu’, ‘softmax’,‘softsign’, ‘softplus’,‘sigmoid’, ‘hard_sigmoid’, ‘exponential’.Only used when hidden_layers=‘custom’.\n\n\noptimizer\nstr\nadam\n\n\n\nepochs\nint\n100\n\n\n\nrandom_state\nNoneType\nNone\n\n\n\nverbose\nint\n0"
  }
]